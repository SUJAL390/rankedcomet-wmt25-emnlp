{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-08-06T01:35:11.148857Z",
     "iopub.status.busy": "2025-08-06T01:35:11.148642Z",
     "iopub.status.idle": "2025-08-06T01:36:38.834610Z",
     "shell.execute_reply": "2025-08-06T01:36:38.833640Z",
     "shell.execute_reply.started": "2025-08-06T01:35:11.148838Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import csv\n",
    "import os\n",
    "import gzip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-06T01:36:49.318835Z",
     "iopub.status.busy": "2025-08-06T01:36:49.318622Z",
     "iopub.status.idle": "2025-08-06T01:37:08.357515Z",
     "shell.execute_reply": "2025-08-06T01:37:08.356683Z",
     "shell.execute_reply.started": "2025-08-06T01:36:49.318815Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "torch.set_float32_matmul_precision('high') \n",
    "import csv\n",
    "import os\n",
    "import gzip\n",
    "\n",
    "DATA_DIR = \".\"\n",
    "COMPRESSED_FILE = \"mteval-task1-test25.tsv.gz\"\n",
    "DECOMPRESSED_FILE = \"mteval-task1-test25.tsv\"\n",
    "\n",
    "compressed_path = os.path.join(DATA_DIR, COMPRESSED_FILE)\n",
    "decompressed_path = os.path.join(DATA_DIR, DECOMPRESSED_FILE)\n",
    "\n",
    "print(f\"Looking for compressed file at: {compressed_path}\")\n",
    "if not os.path.exists(compressed_path):\n",
    "    print(f\"ERROR: File {COMPRESSED_FILE} not found in current directory!\")\n",
    "    print(f\"Current directory contents: {os.listdir(DATA_DIR)}\")\n",
    "    raise FileNotFoundError(f\"Required file {COMPRESSED_FILE} not found\")\n",
    "if not os.path.exists(decompressed_path):\n",
    "    print(f\"Decompressing {COMPRESSED_FILE}...\")\n",
    "    try:\n",
    "        with gzip.open(compressed_path, 'rt', encoding='utf-8') as gz_file:\n",
    "            with open(decompressed_path, 'w', encoding='utf-8') as out_file:\n",
    "                for line in gz_file:\n",
    "                    out_file.write(line)\n",
    "        print(f\"Successfully decompressed to {DECOMPRESSED_FILE}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to decompress file: {e}\")\n",
    "        raise\n",
    "else:\n",
    "    print(f\"Using existing decompressed file: {DECOMPRESSED_FILE}\")\n",
    "\n",
    "print(\"Checking decompressed file content before loading...\")\n",
    "try:\n",
    "    with open(decompressed_path, 'r', encoding='utf-8') as f:\n",
    "        for i in range(5):\n",
    "            line = f.readline()\n",
    "            if not line:\n",
    "                break\n",
    "            print(f\"Line {i+1}: {line.strip()}\")\n",
    "except Exception as e:\n",
    "    print(f\"Failed to read decompressed file: {e}\")\n",
    "    raise\n",
    "\n",
    "print(\"Loading data into Pandas DataFrame...\")\n",
    "try:\n",
    "    df_test = pd.read_csv(\n",
    "        decompressed_path,\n",
    "        sep='\\t',\n",
    "        header=0,\n",
    "        encoding='utf-8',\n",
    "        quoting=csv.QUOTE_NONE\n",
    "    )\n",
    "    print(f\"Successfully loaded and parsed {len(df_test)} segments.\")\n",
    "    print(\"Data Schema Verified:\")\n",
    "    df_test.info()\n",
    "    print(\"\\nFirst 5 rows of test data:\")\n",
    "    print(df_test.head().to_string())\n",
    "except Exception as e:\n",
    "    print(f\"Failed to load data into DataFrame: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-06T01:37:08.358963Z",
     "iopub.status.busy": "2025-08-06T01:37:08.358433Z",
     "iopub.status.idle": "2025-08-06T01:38:25.688743Z",
     "shell.execute_reply": "2025-08-06T01:38:25.687859Z",
     "shell.execute_reply.started": "2025-08-06T01:37:08.358941Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from comet import download_model, load_from_checkpoint\n",
    "\n",
    "MODEL_NAME = \"Unbabel/wmt22-comet-da\"\n",
    "BATCH_SIZE = 4\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Execution device: {device}\")\n",
    "\n",
    "print(f\"Loading SOTA model: {MODEL_NAME}...\")\n",
    "model_path = download_model(MODEL_NAME)\n",
    "model = load_from_checkpoint(model_path).to(device)\n",
    "model.eval()\n",
    "\n",
    "print(\"Formatting data for prediction...\")\n",
    "data_to_score = []\n",
    "for _, row in df_test.iterrows():\n",
    "    src = str(row['source_segment']).replace(' \\\\n ', '\\n')\n",
    "    hyp = str(row['hypothesis_segment']).replace(' \\\\n ', '\\n')\n",
    "    \n",
    "    ref_val = row['reference_segment']\n",
    "    if pd.isna(ref_val) or ref_val == \"NaN\":\n",
    "        ref_content = \"\"\n",
    "    else:\n",
    "        ref_content = str(ref_val).replace(' \\\\n ', '\\n')\n",
    "        \n",
    "    data_to_score.append({\"src\": src, \"mt\": hyp, \"ref\": ref_content})\n",
    "print(f\"Data formatting complete for {len(data_to_score)} entries.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-06T01:38:25.690188Z",
     "iopub.status.busy": "2025-08-06T01:38:25.689557Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(\"Starting prediction... This may take some time.\")\n",
    "with torch.no_grad():\n",
    "    seg_scores, _ = model.predict(\n",
    "        data_to_score,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        gpus=1 if device == \"cuda\" else 0,\n",
    "        progress_bar=True\n",
    "    )\n",
    "print(f\"Prediction finished. Generated {len(seg_scores)} scores.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "SUBMISSION_DIR = \".\"\n",
    "SUBMISSION_FILE_PATH = os.path.join(SUBMISSION_DIR, \"segments.tsv\")\n",
    "\n",
    "print(\"Creating the final submission DataFrame...\")\n",
    "submission_df = df_test[[\n",
    "    'doc_id', 'segment_id', 'source_lang', 'target_lang',\n",
    "    'set_id', 'system_id', 'domain_name', 'method'\n",
    "]].copy()\n",
    "\n",
    "submission_df['overall'] = seg_scores\n",
    "\n",
    "print(f\"Saving submission file to {SUBMISSION_FILE_PATH}...\")\n",
    "submission_df.to_csv(\n",
    "    SUBMISSION_FILE_PATH,\n",
    "    sep='\\t',\n",
    "    index=False,\n",
    "    header=True,\n",
    "    encoding='utf-8'\n",
    ")\n",
    "print(\"--- Submission file created successfully! ---\")\n",
    "\n",
    "print(\"\\nVerifying submission file head:\")\n",
    "print(pd.read_csv(SUBMISSION_FILE_PATH, sep='\\t').head().to_string())"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 8010014,
     "sourceId": 12675019,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31090,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
